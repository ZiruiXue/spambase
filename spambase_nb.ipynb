{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bernoulli Naive Bayes Classifier for Spambase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data file\n",
    "data = pd.read_csv(\"spambase.data\", header=None)\n",
    "data.rename(columns={57:'class'}, inplace=True)\n",
    "y = np.array(data.pop('class'))\n",
    "X = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to shuffle the data. Spliting the data into 5 folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are a popular statistical technique of e-mail filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model from three types naive_bayes classifier\n",
    "# clf = GaussianNB()\n",
    "# clf = clf = MultinomialNB()\n",
    "clf = BernoulliNB()\n",
    "Scores = []\n",
    "acc = []\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    #  split data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    # compute fpr, fnr, accuracy,error\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fpr = fp / (tp + tn + fn + fp)\n",
    "    fnr = fn / (tp + tn + fn + fp)\n",
    "    total = tp + tn + fn + fp\n",
    "    acc.append(score)\n",
    "    Scores.append({\"fp\":fp,\"fn\":fn,\"total\":total,\"false positive(%)\":fpr * 100,\n",
    "                   \"false negative(%)\":fnr * 100,\"accuracy(%)\": score * 100, \"error(%)\": 100 - score*100})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the table of the percentage of false positive, false negative, accuracy and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fp  fn  total  false positive(%)  false negative(%)  accuracy(%)   error(%)\n",
      "0  35  76    921           3.800217           8.251900    87.947883  12.052117\n",
      "1  27  62    920           2.934783           6.739130    90.326087   9.673913\n",
      "2  45  63    920           4.891304           6.847826    88.260870  11.739130\n",
      "3  40  64    920           4.347826           6.956522    88.695652  11.304348\n",
      "4  42  69    920           4.565217           7.500000    87.934783  12.065217\n",
      "Average accuracy:  88.63305480810084 %\n",
      "Average Error: 11.366945191899163 %\n"
     ]
    }
   ],
   "source": [
    "# print each fold's accuracy and error\n",
    "df = pd.DataFrame(Scores, columns=['fp', 'fn','total',\n",
    "                                   'false positive(%)','false negative(%)','accuracy(%)', 'error(%)'])\n",
    "print(df)\n",
    "print(\"Average accuracy: \", np.mean(acc) * 100,\"%\")\n",
    "print(\"Average Error:\", 100 - np.mean(acc) * 100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For binary problemsï¼ŒMultinomial classifier is  more suitable after comparing the results of three types naive bayes classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of Gaussian Naive Bayes:\n",
    "Average accuracy:  82.19997167540008 %\n",
    "Average Error: 17.80002832459992 %\n",
    "\n",
    "The result of Multinomial Naive Bayes:\n",
    "Average accuracy:  79.17837416796488 %\n",
    "Average Error: 20.821625832035124 %\n",
    "\n",
    "For binary problem, compared with three results, Bernoulli Naive Bayes is the most suitable classifier for this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
